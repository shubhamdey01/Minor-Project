{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets rouge_score nltk -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:06:50.698078Z","iopub.execute_input":"2024-11-06T04:06:50.698400Z","iopub.status.idle":"2024-11-06T04:07:06.535566Z","shell.execute_reply.started":"2024-11-06T04:06:50.698365Z","shell.execute_reply":"2024-11-06T04:07:06.534447Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nfrom datasets import load_dataset\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom rouge_score import rouge_scorer\nimport nltk\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:07:20.184849Z","iopub.execute_input":"2024-11-06T04:07:20.185581Z","iopub.status.idle":"2024-11-06T04:07:27.134048Z","shell.execute_reply.started":"2024-11-06T04:07:20.185539Z","shell.execute_reply":"2024-11-06T04:07:27.133135Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Load the pretrained T5-small model and tokenizer\nt5 = \"t5-small\"\nmodel = T5ForConditionalGeneration.from_pretrained(t5)\ntokenizer = T5Tokenizer.from_pretrained(t5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:07:35.889563Z","iopub.execute_input":"2024-11-06T04:07:35.890407Z","iopub.status.idle":"2024-11-06T04:07:40.726961Z","shell.execute_reply.started":"2024-11-06T04:07:35.890362Z","shell.execute_reply":"2024-11-06T04:07:40.726195Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c4cff6fb10c4b32abc3fec0c9820c04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d587c600c03c4f399cba7fc453034902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f033b1d7ff54be38b3ad6230fa4ebbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48cf8f88e0f04f43a3cb23d4256d152e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d1925401b5941c38e272a4c713b8a5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a4686eecae4ca587ef2adfcb352120"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load CNN/DailyMail dataset\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:08:00.148875Z","iopub.execute_input":"2024-11-06T04:08:00.149759Z","iopub.status.idle":"2024-11-06T04:08:19.245190Z","shell.execute_reply.started":"2024-11-06T04:08:00.149715Z","shell.execute_reply":"2024-11-06T04:08:19.244282Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"928059c80e2045599ecd59bb9bf1a749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b476722f723405cac214848a187b8fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d5bb514c34940d2a6212055ce570024"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373a44f216b6440e9948eb4dbdb518e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e443e572418467aaa05466a4b2d2cba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d9ddaa1ed9437cb94b2d63c3b0b1e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca05bd7460243b3a8095a061f2c77b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"051a0054c675487ba844b33c78f5015d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0092f59e4a1e4738a33c46e17d99f32c"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 287113\n    })\n    validation: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 13368\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 11490\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"test = dataset[\"test\"]\ntest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:08:23.378609Z","iopub.execute_input":"2024-11-06T04:08:23.379237Z","iopub.status.idle":"2024-11-06T04:08:23.385716Z","shell.execute_reply.started":"2024-11-06T04:08:23.379197Z","shell.execute_reply":"2024-11-06T04:08:23.384456Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['article', 'highlights', 'id'],\n    num_rows: 11490\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Function to generate summaries using T5\ndef generate_summary_batch(texts):\n    inputs = tokenizer([\"summarize: \" + text for text in texts], return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n    input_ids = inputs[\"input_ids\"].to(model.device)\n    attention_mask = inputs[\"attention_mask\"].to(model.device)\n\n    # Generate summaries in batches\n    summaries = model.generate(input_ids, attention_mask=attention_mask, max_length=150, num_beams=5, length_penalty=2.0, early_stopping=True)\n    return tokenizer.batch_decode(summaries, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:08:43.936235Z","iopub.execute_input":"2024-11-06T04:08:43.937305Z","iopub.status.idle":"2024-11-06T04:08:43.943146Z","shell.execute_reply.started":"2024-11-06T04:08:43.937255Z","shell.execute_reply":"2024-11-06T04:08:43.942229Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Function to compute ROUGE scores\ndef compute_rouge(predictions, references):\n    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n    rouge_results = {\n        \"rouge1\": [],\n        \"rouge2\": [],\n        \"rougeL\": []\n    }\n    for pred, ref in zip(predictions, references):\n        scores = scorer.score(ref, pred)\n        rouge_results[\"rouge1\"].append(scores[\"rouge1\"].fmeasure)\n        rouge_results[\"rouge2\"].append(scores[\"rouge2\"].fmeasure)\n        rouge_results[\"rougeL\"].append(scores[\"rougeL\"].fmeasure)\n    return {metric: sum(scores) / len(scores) for metric, scores in rouge_results.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:08:49.420875Z","iopub.execute_input":"2024-11-06T04:08:49.421689Z","iopub.status.idle":"2024-11-06T04:08:49.431870Z","shell.execute_reply.started":"2024-11-06T04:08:49.421620Z","shell.execute_reply":"2024-11-06T04:08:49.430743Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Function to compute BLEU score\ndef compute_bleu(predictions, references):\n    pred_tokens = [nltk.word_tokenize(pred.lower()) for pred in predictions]\n    ref_tokens = [[nltk.word_tokenize(ref.lower())] for ref in references]\n    return corpus_bleu(ref_tokens, pred_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:09:02.363657Z","iopub.execute_input":"2024-11-06T04:09:02.364484Z","iopub.status.idle":"2024-11-06T04:09:02.369465Z","shell.execute_reply.started":"2024-11-06T04:09:02.364442Z","shell.execute_reply":"2024-11-06T04:09:02.368345Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Create DataLoader for batching\ndef create_dataloader(dataset, batch_size=8):\n    def collate_fn(batch):\n        texts = [example[\"article\"] for example in batch]\n        references = [example[\"highlights\"] for example in batch]\n        return texts, references\n\n    return DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:09:30.789742Z","iopub.execute_input":"2024-11-06T04:09:30.790661Z","iopub.status.idle":"2024-11-06T04:09:30.796144Z","shell.execute_reply.started":"2024-11-06T04:09:30.790605Z","shell.execute_reply":"2024-11-06T04:09:30.795206Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Set batch size and create DataLoader\nbatch_size = 8\ndataloader = create_dataloader(test, batch_size)\n\nall_generated_summaries = []\nall_references = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:09:54.753084Z","iopub.execute_input":"2024-11-06T04:09:54.754052Z","iopub.status.idle":"2024-11-06T04:09:54.758694Z","shell.execute_reply.started":"2024-11-06T04:09:54.753991Z","shell.execute_reply":"2024-11-06T04:09:54.757742Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Ensure model is in evaluation mode and move to GPU if available\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:10:01.028239Z","iopub.execute_input":"2024-11-06T04:10:01.028635Z","iopub.status.idle":"2024-11-06T04:10:01.360585Z","shell.execute_reply.started":"2024-11-06T04:10:01.028598Z","shell.execute_reply":"2024-11-06T04:10:01.359594Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Evaluate in batches\nfor batch in tqdm(dataloader, desc=\"Evaluating\"):\n    texts, references = batch\n    generated_summaries = generate_summary_batch(texts)\n    all_generated_summaries.extend(generated_summaries)\n    all_references.extend(references)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:10:15.799235Z","iopub.execute_input":"2024-11-06T04:10:15.799619Z","iopub.status.idle":"2024-11-06T05:03:29.456281Z","shell.execute_reply.started":"2024-11-06T04:10:15.799581Z","shell.execute_reply":"2024-11-06T05:03:29.455364Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 1437/1437 [53:13<00:00,  2.22s/it]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Compute ROUGE and BLEU scores\nrouge_scores = compute_rouge(all_generated_summaries, all_references)\nbleu_score = compute_bleu(all_generated_summaries, all_references)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:05:24.463904Z","iopub.execute_input":"2024-11-06T05:05:24.464309Z","iopub.status.idle":"2024-11-06T05:06:33.978433Z","shell.execute_reply.started":"2024-11-06T05:05:24.464260Z","shell.execute_reply":"2024-11-06T05:06:33.977302Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Print the results\nprint(\"ROUGE Scores:\")\nfor metric, score in rouge_scores.items():\n    print(f\"{metric}: {score:.4f}\")\n\nprint(f\"BLEU Score: {bleu_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:06:46.922077Z","iopub.execute_input":"2024-11-06T05:06:46.922955Z","iopub.status.idle":"2024-11-06T05:06:46.928094Z","shell.execute_reply.started":"2024-11-06T05:06:46.922912Z","shell.execute_reply":"2024-11-06T05:06:46.927245Z"}},"outputs":[{"name":"stdout","text":"ROUGE Scores:\nrouge1: 0.3867\nrouge2: 0.1724\nrougeL: 0.2726\nBLEU Score: 0.1445\n","output_type":"stream"}],"execution_count":15}]}